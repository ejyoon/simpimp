---
title: "Developmental Gains in Speed and Accuracy in the Processing of Ad-Hoc Implicatures"
short-title: "Children's ad-hoc implicature processing"
output: kmr::apa_manuscript
csl: apa6.csl
bibliography: simpimp.bib

document-params: "a4paper,man,apacite,floatsintext"

bib-tex: "simpimp.bib"

author-information:
    - \author{Erica J. Yoon, Michael C. Frank}

affiliation-information:
    # Single affiliation
    - \affiliation{Department of Psychology, Stanford University}

author-note:
    "We would like to acknowledge Asher Kaye and Stephanie Hsiang for their assistance in data collection, and thank the staff and families at Children's Discovery Museum of San Jose and Bing Nursery School.    
Address all correspondence to Erica J. Yoon, Stanford University, Department of Psychology, Jordan Hall, 450 Serra Mall (Bldg. 420), Stanford, CA, 94305. E-mail: ejyoon@stanford.edu."

abstract: 
    "Language comprehension often requires making *implicatures*: for example, inferring that “I ate some of the cookies” implies the speaker ate some *but not all* (scalar implicatures); and “I ate the chocolate-chip cookies” where there are both chocolate chip cookies and raisin cookies in the context implies that the speaker ate the chocolate chip, *but not both the chocolate chip and raisin cookies* (ad-hoc implicatures). Developmental work have reported mixed results about the development of implicature processing abilities. In the current work we use time-sensitive methods (eye-tracking and tablet) to examine developmental gains in children’s ad-hoc implicature processing, and test whether one cause of toddlers’ consistent failure to process implicature is their difficulty with executive function - specifically inhibitory control to inhibit responses toward a salient distractor (*inhibitory hypothesis*). Across three experiments, we present evidence for successful implicature computation by children as young as 3 years, substantial developmental gains in implicature computation from 2 to 5 years in both paradigms, and support for the inhibitory hypothesis. Our work contributes to the growing literature of early signs of pragmatic understanding in children."
    
keywords:
    "Pragmatics; cognitive development; language processing; implicature; inhibitory control; eye-tracking; tablet
"
---

```{r global_options, include=FALSE}
rm(list=ls())
knitr::opts_chunk$set(fig.width=4.5, fig.height=5, fig.crop = F, fig.path='figs/',
                      echo=FALSE, warning=FALSE, cache=T, message=FALSE, sanitize = T)
```

```{r libraries}
rm(list = ls())
library(ggplot2)
library(lme4)
library(data.table)
library(dplyr)
library(tidyr)
library(directlabels)
library(xtable)
library(readr)
library(langcog) # Langcog Lab useful R functions -- www.github.com/langcog/langcog
theme_set(theme_bw())
```

```{r calldata_, message=FALSE, include=FALSE}
d_et <- rbind(
  read_csv("../eye-tracking/processed_data/simpimp_processed_2v1.csv"),
  read_csv("../eye-tracking/processed_data/simpimp_processed_3v1.csv")) %>%
  mutate(trial_type = factor(trial_type, labels = c("control-double", "control-single", "inference")),
         age_group = as.factor(age_group),
         expt = factor(expt, labels = c("2-vs-1", "3-vs-1")),
         subid = as.factor(subid),
         t.crit = as.numeric(as.character(t.crit)))
#         targetAtOnset = as.factor(targetAtOnset)

## targetAtOnset: Indicate where subject was looking at during word onset
onset <- d_et %>%
  select(subid, stimulus, t.crit, correct) %>%
  filter(t.crit > - 0.004 & t.crit < 0.004) %>%
  mutate(targetAtOnset = ifelse(correct == TRUE, TRUE, FALSE)) %>%
  select(subid, stimulus, targetAtOnset) %>%
  distinct(subid, stimulus)
d_et <- left_join(d_et, onset)

## subsample the data so that you get smooth curves***
subsample.hz <- 30 
d_et <- d_et %>%
  mutate(t.crit.binned = round(t.crit*subsample.hz)/subsample.hz) %>%
  mutate(t.crit.binned = signif(t.crit.binned, 4))
head(d_et)

d_ip <- read_csv("../ipad/simpimp_ipad_short.csv")

subj_notenoughtrials <- d_ip %>%
    group_by(subid) %>%
    summarise(nrow=n()) %>%
    filter(nrow < 10)   

d_ip <- d_ip %>%
  filter(!subid %in% subj_notenoughtrials$subid) %>%
  mutate(expt = "ipad") %>%
  filter(trial_type != "practice",
         age_group != "1",
         age_group != "6") %>%
  mutate(trial_type = factor(trial_type, labels = c("control-double", "control-single", "inference"))) %>%
  mutate(
    subid = as.factor(subid),
    age_group = as.factor(age_group), 
    item_num = as.factor(item_num),
    item_rel = as.factor(item_num),
    correct = as.factor(correct),
    correct = factor(correct, labels=c("0","1")),
    correct = as.numeric(as.character(correct)))
levels(d_ip$item_rel) <- c("fewer", "fewer", "more", "more")
head(d_ip)
```

```{r cliprt, include=FALSE}
# remove outliers, by rt
top_bound <- mean(log(d_ip$rt)) + 3*sd(log(d_ip$rt))
bottom_bound <- mean(log(d_ip$rt)) - 3*sd(log(d_ip$rt))

d_ip <- d_ip %>%
  filter(log(rt) < top_bound, 
         log(rt) > bottom_bound)

et_rts <- d_et %>%
  filter(t.crit > 0, targetAtOnset == FALSE & correct == TRUE) %>%
  group_by(subid, expt, trial_type, age_group, stimulus) %>%
  summarize(rt = min(t.crit))

# remove outliers, by rt
top_bound <- mean(log(et_rts$rt)) + 3*sd(log(et_rts$rt))
bottom_bound <- mean(log(et_rts$rt)) - 3*sd(log(et_rts$rt))

et_rts <- et_rts %>%
  filter(log(rt) < top_bound, 
         log(rt) > bottom_bound)
```

# Introduction 

Language comprehension often requires inferring speakers’ intended meanings that go beyond the literal meanings of what they say. In @grice1975logic’s account, conversation is a cooperative act: A speaker will cooperatively choose utterances such that the listener can understand the intended message, and the listener will interpret the utterance with this assumption of the speaker’s cooperativeness in mind. According to @grice1975logic, a key maxim observed in cooperative communication is that the speaker makes the contribution as informative as is required by the conversation at hand. Thus, expecting a cooperative speaker to have produced a maximally informative utterance, the listener can make inferences that go beyond the literal meanings of the speaker’s words. 

The non-literal meanings computed through these inferential processes are called pragmatic implicatures. For example, “I ate some of the cookies” implies that the speaker ate some but not all of the cookies, because a cooperative speaker who ate all would have said “all,” which is more informative than the weaker alternative “some.” This is an example of a scalar implicature, in which use of a weaker term (“some”) in a lexical scale negates a stronger alternative (“all”). Another kind of implicature is context-based, ad-hoc implicatures: “I ate the chocolate chip cookies” in a context where two kinds of cookies are available, chocolate chip and raisin, implies that the speaker ate the chocolate-chip but not both the chocolate chip cookies and raisin cookies. In this case, the context sets up a contrast between the term offered (“chocolate chip cookie”) and the stronger alternative to be negated (“chocolate chip and raisin cookies”)^[@grice1975logic calls these implicatures *generalized* (scalar) vs. *particularized* (ad-hoc), but we use a theory-neutral designation here.
]. 

Simple implicatures like these have been an important case study for pragmatics more broadly. Both classic, informal models of communication [e.g., @grice1975logic; @sperber1986] and more recent probabilistic models of pragmatic inference [e.g., @frank2012; @goodman2013] describe the processes that language users use to compute such implicatures. And a rich psycholinguistic literature has measured adults’ processing of implicatures relative to literal interpretations and found that adults robustly compute implicatures, albeit more slowly than unambiguous literal meanings [@bott2012; @breheny2013; @huang2009a].


How does the ability to make implicatures develop? Since implicature computation is an important indicator of broader pragmatic understanding, many studies have extensively tested children’s abilities. To date, findings have been mixed, with children especially struggling with scalar implicatures. For example, in @papafragou2003’s study, a puppet saw three out of three horses jumped over a fence, and described the scene by saying “Some of the horses jumped over the fence.” When asked whether the statement is a good description of the context at hand, adults rejected the infelicitous statement whereas children mostly accepted it, which suggested that children failed to compute *some* vs. *all* implicatures (though see @katsos2011, for an alternative explanation). Besides struggling with *some* vs. *all* [@huang2009b; @hurewitz2006; @noveck2001], children have consistently failed to compute implicatures involving scalar contrasts, including *a* vs. *some* [@barner2009], *might* vs. *must* [@noveck2001], and *or* vs. *and* [@chierchia2001].

While children struggle on many scalar implicature tasks, they tend to be more successful at computing ad-hoc implicatures (which depend on context, rather than lexical scales). One potential difficulty in a typical scalar implicature task is the need to generate relevant alternatives to a given scalar term. For children to hear “some of the horses jumped over the fence” and derive the implicature “some *but not all*,” they must first realize that “all” is the relevant alternative to “some”. @barner2011 argued that children’s failures in the scalar implicature tasks are due to their lack of ability to spontaneously generate the alternative to negate upon hearing the term offered. @barner2011’s claim predicts that children’s implicature computation should improve when they can access the relevant alternatives. Consistent with this hypothesis, children show substantially improved implicature computation in ad-hoc implicature tasks – which provided access to relevant alternatives in context – compared to scalar implicature tasks [@horowitzSchneider; @katsos2011; @papafragou2004; @stiller2015]. 

For example, @stiller2015 showed 2.5- to 5-year-old children three different faces: a face with no item; a face with only glasses; and a face with glasses and top-hat, and asked children to choose one of the three faces as the referent in a puppet’s statement, “My friend has glasses.” Thus there was no need for children to spontaneously generate the alternative (“glasses and top-hat”) to the term used (“glasses”) because the alternative was visible in the context. In this task, children as young as 3.5 years chose the face with only glasses as the referent, which shows they successfully computed the implicature that the puppet’s friend has “glasses *but not both glasses and top-hat*.” Similarly, in @horowitzSchneider’s study that tested both children’s scalar and ad-hoc implicature computation, 4-year-olds successfully made ad-hoc implicatures, but performed poorly on scalar implicatures. 

Despite older children’s success, toddlers below 3 years struggle with ad-hoc implicatures. Even @stiller2015’s paradigm, which found evidence of implicatures in the youngest ages to date, 2.5- and 3-year-olds still failed to compute implicatures. But does this finding imply that the young toddlers lack pragmatic understanding, specifically an awareness of the need for informativeness in cooperative communication? On the contrary, children are sensitive to informativeness in communication: From age two onward, when they are asked to produce referring expressions, children recognize the level of referential ambiguity and attempt to provide more information through speech and gestures when the ambiguity level is greater [@matthews2012; @oneill2001]. Hence, lack of sensitivity to the need for communicative informativeness does not seem to be the problem for toddlers’ implicature processing. So what causes toddlers’ failures in ad-hoc implicature tasks?

One potential candidate is children’s lack of inhibitory control, or inability to inhibit their selection of salient objects in the context. Scalar implicature is typically described as requires rejecting a stronger meaning (e.g., “all”) and adding its negation to the weaker term (e.g., “some but not all”). In a task based on referent selection, participants need to suppress selecting a distractor that represents the stronger meaning, and thus has a larger set size (all of the cookies) or more features (hat and glasses) and is more salient. Instead they must choose a less salient target that represents the weaker meaning (some of the cookies, glasses only). This kind of task may be challenging to children because their executive function – specifically their ability to inhibit responses to salient targets – is not yet fully developed [@davidson2006; @diamond1996].

Processing measures may help to identify potential sources of difficulty in pragmatic tasks, including issues in inhibitory control. Many previous implicature tasks have measured only the accuracy of children’s responses. For example, studies often use as their sole dependent measure  whether children correctly judge a statement to be felicitous or infelicitous, or whether they accurately select a felicitous referent (*target*) vs. an incorrect counterpart (*distractor*). Since implicature has been argued to be a time-consuming computation [at least in some contexts; @bott2012; @huang2009a], adding a time dimension to these accuracy measures might help provide a fuller account of children’s inferential process. In particular, examining children’s allocation of attention to targets and distractor at different phases of utterance processing might help identify specific aspects of the task as contributing to children’s decision-making process (e.g., the salience of a particular target). 

Eye-tracking and tablet paradigms allow analyses of accuracy and reaction time measures. Eye-tracking allows moment-by-moment analysis of the trajectory of eye gaze, which may provide insight into children’s reasoning at intermediate stages of the inferential process. For example, one set of implicature tasks used eye-tracking to show that both adults and children were delayed in identifying the inferential (compared to unambiguous) target; however, adults, but not children, computed scalar implicatures rapidly enough to identify the inferential target before the referent is semantically (literally) disambiguated in the utterance [@huang2009a; @huang2009b]. Thus, eye-tracking makes it possible to compare group performances at a precise time interval given. While they do not yield moment-to-moment trajectories, tablet paradigms have some of the advantages of both naturalistic and time-sensitive paradigms. They resemble studies with storybook stimuli that are familiar to children, and interaction with the touchscreen keeps the task engaging. Tablets also make it possible to record the amount of time before the subject made a decision, allowing time-sensitive analyses of children’s pragmatic processing [@frank2016].

Consistent with the idea that some type of inhibitory control issue might play a role in children’s implicature computation, other eye-tracking studies of language processing have shown that young children have difficulty in allocating attention toward targets that are less perceptually salient [e.g., @hollich2000; @nordmeyer2014; @pruden2006; @yurovsky2015]. For example, in @yurovsky2015, 1.5- to 2-year-olds showed evidence of word learning when the target (the correct referent of the newly-learned word) and distractor (previously unnamed named object) were matched in perceptual salience, but when salience was greater for the distractor, word learning abilities were masked at test by an overall bias to look at the distractor. It seems quite possible that the same difficulties arose in previous studies of implicature processing for slightly older children.  

For testing this *inhibitory hypothesis*, ad-hoc implicature tasks based on referent selection can be especially useful, as they allow for easy manipulation of the relative salience of potential referents in the context. For instance, in the @stiller2015 paradigm reviewed above, the target (face with only glasses) was less salient than the distractor (face with glasses and top-hat), since the distractor had one extra feature (top-hat). It would have been possible to increase the distractor’s salience even further by adding another feature (e.g. face with glasses, top-hat, *and scarf*). 

Such a salience manipulation has interesting implications, as it is predicted to lead to an advantage for the distractor based on salience only, but it leads to the opposite prediction – an advantage for the target – based on pragmatic implicature. That is, given the utterance “My friend has glasses,” the increased number of features on the referent that are not named (top-hat *and* scarf) leads to lower likelihood of the distractor being the referent, and thus leads to a strengthened implicature [@frank2012; @frank2014]. Thus, a salience manipulation such as one described above creates a salience-pragmatics tradeoff, where the increased salience contrast will lead children to pay more attention to the more salient distractor under a salience-based processing strategy, or the contrast will lead them to correctly identify the target, or the referent of the strengthened implicature, under a pragmatics-based processing strategy. 

The current paper has three interlocking goals. First, we aimed to replicate findings of 3- to 5-year-olds’ computation of ad-hoc implicatures using a new paradigm and new stimuli.  Second, we aimed to collect data using timing-sensitive eye-tracking and tablet paradigms in order to help identify possible reasons for toddlers’ struggle with implicature computation. Third, through manipulation of the salience contrast between inferential targets and distractors (as discussed above), we aimed to test the hypothesis that younger children’s difficulty with implicature is caused by their inability to inhibit responses to more salient objects. 

# Experiment 1A

In Experiment 1A, we used an eye-tracking paradigm to confirm the previous findings for the development of ad-hoc implicature processing – that preschoolers can compute ad-hoc implicatures. We also explored processing measures to examine developmental gains relevant to implicature processing, and try to find potential causes of younger children’s struggle. 

We adopted the referent selection method, in which participants were asked to select a referent among a set of candidates. As mentioned earlier, referent selection paradigms showed evidence of successful implicature computation in youngest children to date [@horowitzSchneider; @stiller2015]. We yoked the referent selection method to an eye-tracking paradigm, to examine children’s eye gazes and closely investigate the search process for the target referent. Compared to previous studies, we reduced the number of potential referents in context to simplify the task even more: In Stiller et al.’s paradigm, there were three potential referents in the context (face with no item, face with only glasses, face with glasses and a top-hat); in our current paradigm, we presented two instead of three potential referents (e.g. plate with only a carrot and plate with a carrot and banana). This simplification minimized the extraneous cognitive load for children and ensured seeing clearer eye-gaze trajectory patterns. 


## Method

### Participants

Parents and their 2- to 5-year-old children visiting Children's Discovery Museum in San Jose, CA, were invited to participate in a short video study. A total of 150 children were recruited but a few of them were excluded from the sample for the following reasons: age other than 2 to 5 years (*n* = 11), parent-reported English exposure less than our prespecified criterion of 75% (*n* = 11), noncompliance or difficulty with the experimental procedure (*n* = 7), experimenter error or technical issues (*n* = 4). In addition, individual trials with more than 40% missing gaze data were excluded from analysis, and only participants who completed at least 60% of the trials (10 out of 16) according to this criterion were included in the analysis. These exclusion criteria led to a final sample of 117 (out of 127 participants who qualified; see Table 1). Children were given a sticker for participating in the study. We also tested fourteen adult participants, undergraduate students recruited through Stanford Psychology credit pool. 

```{r expt1summarytab, echo = F, results = 'asis'}

experiment <-c("Expt 1A", " ", " ", " ", "Expt 1B", " ", " ", " ","Expt 2", " ", " ", " ")
age_group <- c("2", "3", "4", "5", "2", "3", "4", "5", "2", "3", "4", "5")
mean_age <- c("2.6", "3.5", "4.5", "5.4", "2.6", "3.5", "4.4", "5.5", "2.5", "3.5", "4.4", "5.3")
total <- c("23", "32", "28", "34", "25", "22", "29", "24", "25", "29", "25", "19")
girls <- c("9", "21", "14", "15", "16", "10", "15", "9", "18", "16", "8", "11")
keep_rate <- c("0.93", "0.94", "1.00", "1.00", "0.97", "0.91", "1.00", "0.88", "0.86", "0.97", "0.96", "1.00")
e0.tab <- data.frame(experiment, age_group, mean_age, total, girls, keep_rate)
colnames(e0.tab) <- c("", "Age bin", "Mean (years)", "Participants", "Girls", "Proportion kept")

print(xtable(e0.tab,
             align = c("l", "l","c","c","c", "c","c"),
             label = "tab:exp1_summary",
             caption = "Demographic information of participants in Experiments 1A and 1B, and proportion of participants who are qualified and complete the study that are included in the analyses."),
      include.rownames=FALSE,hline.after=c(0,nrow(e0.tab)),
      sanitize.text.function=function(x){x},
      caption.placement = 'bottom', 
      table.placement = "tb",
      comment = F)
```

### Stimuli and Design

On each trial, participants saw two images: a target and distractor, which could either be an item with a single feature (e.g. a plate with only a carrot or only a banana), or an item with double features (e.g., a plate with a carrot and a banana). Each trial contained three phases: in the initial phase (8.5 seconds), two images were presented in silence for two seconds, then a pre-recorded voice said a sentence (e.g. "Look at these plates. Elmo's plate has a carrot."). Then, in the anticipatory phase (1.5 seconds), a chime sound played to induce participants' anticipatory gaze. In the following feedback phase (1.5 seconds), a character appeared next to the target with an amusing sound effect. This outcome served to keep the task engaging for participants.

There were three types of test trials (shown in Figure 1). In *inference* trials, the target item had a single feature (e.g., a carrot), and the distractor item had two features, one that was common with the target (e.g., a carrot) and the other feature that was unique (e.g., a banana). The test sentence named the feature that was common to the target and distractor. Thus, if participants understood that "Elmo's plate has a carrot" implicates "Elmo's plate has a carrot *but not a banana*," given the context, they should look more toward the target than the distractor, but otherwise look equally to both.

There were two additional trial types, with semantically unambiguous targets: *Control-double* trials looked identical to inference trials, but the target and distractor were switched, such that the double-feature item was the target and the single-feature item was the distractor, and the test sentence named the unique feature on the target. *Control-single* trials presented two items that each had a unique single feature, and either could be the target. Children saw 4 inference, 4 control-double, and 8 control-single trials; adults saw 6 inference, 6 control-double, and 12 control-single trials. 

There were six sets of item and feature types, and the features were named with nouns found on the  MacArthur-Bates Communicative Development Inventory word list [@fenson1994]. Two orders of the test trials were created, such that trial types and item types were counterbalanced and trial order was pseudo-randomized across the two orders.

### Procedure

Participants sat in a booster seat, approx. 60 cm away from the monitor of an SMI RED 120 Hz binocular remote eye-tracker. Participants were introduced to the task as watching a short video. The video began with a short Elmo video clip that lasted for 1-2 minutes, during which any necessary adjustments to the eye-tracker and participants' chair positions were made. The eye-tracker was then calibrated using a 2-point calibration and validation of the calibration points. Then participants were introduced to Sesame Street characters and told "Today, [they] will show us lots of fun things. Are you ready? Let's go!" Following the introduction, participants saw two gaze-contingent practice trials, with unambiguous targets that differed from the test items. Then children watched 16 test trials and adults watched 24 test trials, as well as 4 filler photos of children playing and 2 Elmo video clips, presented at a pseudo-random points between test trials. The video lasted approximately 8 minutes.

## Results

```{r et_acc, fig.pos = "H", echo=FALSE, message=FALSE, fig.width = 6, fig.height = 4, fig.align='center', fig.cap='Proportion of 2- to 5-year-old children and adults looking to the target image as the utterance unfolds in Experiments 1A and 1B (rows), in different trial types (columns). Time 0 represents the target word onset, and time 0.78 represents the average target word offset. Proportion correct looking is defined by looks to the target divided by the total looks to both the target and the distractor. Example stimuli are shown in the bottom right hand corner for each condition; the named character emerged at the end of the trial to mark the correct target.'}
grid::grid.raster(png::readPNG("figs/et-accuracy.png"))
```

```{r expt1ttest, include=FALSE}
ms <- d_et %>%
  filter(t.crit > 0.78 & t.crit <= 3) %>%
  group_by(expt, trial_type, age_group, subid) %>%
  summarise(correct = mean(correct, na.rm = TRUE))

# t-tests for inference trials, by age
expt1.ttest.acc.2y = t.test(filter(ms, expt == "2-vs-1" & age_group == "2" & trial_type == "inference")$correct, mu=.5)
expt1.ttest.acc.3y = t.test(filter(ms, expt == "2-vs-1" & age_group == "3" & trial_type == "inference")$correct, mu=.5)
expt1.ttest.acc.4y = t.test(filter(ms, expt == "2-vs-1" & age_group == "4" & trial_type == "inference")$correct, mu=.5)
expt1.ttest.acc.5y = t.test(filter(ms, expt == "2-vs-1" & age_group == "5" & trial_type == "inference")$correct, mu=.5)

# referents for 2yr
expt1.ttest.acc.2y.df = round(expt1.ttest.acc.2y$parameter, 2)
expt1.ttest.acc.2y.t = round(expt1.ttest.acc.2y$statistic, 2)
expt1.ttest.acc.2y.p = round(expt1.ttest.acc.2y$p.value, 3)

# referents for 4yr
expt1.ttest.acc.4y.df = round(expt1.ttest.acc.4y$parameter, 2)
expt1.ttest.acc.4y.t = round(expt1.ttest.acc.4y$statistic, 2)
expt1.ttest.acc.4y.p = round(expt1.ttest.acc.4y$p.value, 3)
```

### Accuracy

First, we looked at the rate of accurate looking toward the target in each of trial types. Participants of all ages looked to the targets in both control-double and control-single trials reliably above chance (50%; Figure 1). Children of 4 years and above robustly looked to targets in inference trials (for 4-year-olds: $t$(`r expt1.ttest.acc.4y.df`) = `r expt1.ttest.acc.4y.t`, $p$ =`r expt1.ttest.acc.4y.p`). For example, upon hearing "Bert's plate has a carrot," 4-year-olds looked to the plate with only a carrot more than the plate with a carrot and a banana. 

There were two additional interesting trends in children’s looking patterns: First, 2-year-olds did not disengage from distractors relative to their baseline bias prior to hearing the target word (also see Appendix), and were marginally *below* chance in their overall performance ($t$(`r expt1.ttest.acc.2y.df`) = `r expt1.ttest.acc.2y.t`, $p$ = `r expt1.ttest.acc.2y.p`). Second, even though older children’s correct look to inferential target exceeded look to distractor, it was lower than expected from previous studies; in @stiller2015’s paradigm, for instance, 4-year-olds selected the correct referent at approximately 75%, whereas in the current paradigm, even 5-year-olds looked to the target barely above 60%.

```{r expt1tab, echo = F, results = 'asis'}
# accuracy
ms <- d_et %>%
  filter(age_group != "adult") %>%
  mutate(age_group = as.numeric(as.character(age_group)),
         trial_type = relevel(trial_type, ref = "control-single")) %>%
  filter(t.crit > .8 & t.crit <= 3) %>%
  group_by(expt,trial_type, age_group, subid, stimulus) %>%
  summarise(correct = mean(correct, na.rm = TRUE))

expt1.acc.lmer <- lmer(correct ~ trial_type * age_group + (trial_type | subid) + (age_group | stimulus), 
                       data = filter(ms, expt == "2-vs-1"))

e1.tab <- as.data.frame(summary(expt1.acc.lmer)$coef)

e1.tab$Predictor <- c("Intercept",
                      "Control-double",
                      "Inference",
                      "Age",
                      "Control-double * Age",
                      "Inference * Age")
rownames(e1.tab) <- NULL
e1.tab <- e1.tab[,c(4,1:3)]
names(e1.tab)[4] <- c("$t$ value")

print(xtable(e1.tab,
             align = c("l","l","r","r", "r"),
             label = "tab:exp1_tab",
             caption = "Predictor estimates with standard errors and significance information for a linear mixed-effects model predicting accurate looking to target in Experiment 1A."),
      include.rownames=FALSE,hline.after=c(0,nrow(e1.tab)),
      sanitize.text.function=function(x){x},
      caption.placement = 'bottom', 
      table.placement = "tb",
      comment = F)

```

We fit a linear mixed-effects model^[All mixed-effects models were run using the ``lme4`` package, version 1.1-10 [@bates2014lme4]. The random effects structure for this model was as follows: ``(trial type | subid) + (age | item)`` All of our data and processing and analysis code can be viewed in the version control repository for this paper at: https://github.com/ejyoon/simpimp.] to measure the effects of trial type and age on the proportion of children looking to the target between 0.8 and 4 seconds after the target noun onset (Table 2). We selected this time window because participants would have to wait until the end of target noun (0.8 seconds on average) to know they should switch to the inferential target, given the absence of a disambiguating continuation (e.g., “Elmo’s plate has a carrot and banana.”). The mixed model found a significant main effect of trial type and main effect of age: participants looked to the target significantly less in inference trials compared to control-single trials, and across all trial types, participants’ looking to target increased with age.

One potential concern was that after each trial, feedback was given to indicate which of the two potential referents was the target, and thus it was possible that participants learned to identify the target based on the feedback. A linear mixed-effects model predicting accuracy based on order (first vs. second half of the trials) and age indicated no significant main effect of order, and no interaction between age and order (largest $\beta$ = 0.061, $p >.20$).


```{r expt1rt}
et_rt_ms <- et_rts %>%
  ungroup() %>%
  filter(age_group != "adult") %>%
   mutate(age_group = as.numeric(as.character(age_group)),
         trial_type = relevel(as.factor(trial_type), ref = "control-single")) %>%
  group_by(trial_type, expt, age_group, stimulus, subid) %>%
  summarise(rt = mean(rt))

expt1.rt.lmer <- lmer(rt ~ trial_type * age_group + (trial_type | subid) + (age_group | stimulus), data=filter(et_rt_ms, expt == "2-vs-1"))

expt1.rt.inf.beta <- round(summary(expt1.rt.lmer)$coef[3], 2)
expt1.rt.age.beta <- round(summary(expt1.rt.lmer)$coef[4], 2)
expt1.rt.int.beta <- round(summary(expt1.rt.lmer)$coef[6], 2)

```

### Switch time

Next, we wanted to look at the participants’ processing speed: how quickly they made their responses upon hearing the utterance. For this, we selected trials on which participants were looking at the distractor at the point of disambiguation, and measured the average length of time prior to a switch to the target [@fernald2008].

A linear mixed-effects model measuring the effects of trial type and age on switch time^[with the same random effects as the model for predicting accuracy] as revealed significant main effects of trial type ($\beta$ = `r expt1.rt.inf.beta`, $p =.004$) and age ($\beta$ = `r expt1.rt.age.beta`, $p =.004$) on the average RT, with no interaction (largest $\beta$ = `r expt1.rt.int.beta`, $p >.24$). Inference trials were overall slower than control trials, and participants reacted faster with increasing age in all trial types. 

```{r et_ons, fig.pos = "H", echo=FALSE, message=FALSE, fig.width = 6, fig.height = 4, fig.align='center', fig.cap='Onset contingency plot showing results from Experiments 1A and 1B. Trials were divided depending on where the participant was first looking: the green line indicates trials in which participants looked at distractor first and made switch to target, and orange line target first and switched to distractor. the size of the green shaded region indicates more switches made from distractor-to-target than target-to-distractor. The size of the orange shaded region represents more switches made from target-to-distractor than distractor-to-target.'}
grid::grid.raster(png::readPNG("figs/et-onsetcont_fill2.png"))
```

One question is whether 2-year-olds had difficulty switching correctly from the distractor to target, or whether they switched incorrectly away from the target to distractor. To explore this question, we looked at target- and distractor-initial trials separately, contingent on which item the child was looking toward from the onset of the target noun [@fernald2010]. The top panels in Figure 2 show the mean proportion of participants that switched from where they started in Experiment 1A. Thus, the increase in shift on distractor-initial trials is a correct response, whereas increase in shift on target-initial trials is an incorrect response. 

Across all age groups, there was an initial increase in shift for both target-initial and distractor-initial trials, until the offset of the target word. Then age groups diverged in their looking pattern, and two-year-olds' struggle was evident: whereas older children's switches to distractor decreased and switches to target increased, two-year-olds' switches to distractor continued to *increase* after the target offset, whereas shift from distractor to target stayed the same. 

## Discussion

In Experiment 1A, we replicated previous finding that children of 4 years and older compute ad-hoc implicatures. We additionally confirmed that children of 2 to 5 years successfully compute unambiguous familiar meanings online [@fernald1998]. However, we found that across all ages, rates of correct looking in inference trials were lower than accuracy rates reported in previous studies. This may be due to a methodological limitation of eye-tracking, namely that participants can constantly switch their attention back and forth between potential referents, especially within the context of ambiguous meaning, instead of making a single decision to be for a one-time response to be recorded. We return to this issue in Experiment 2.

Consistent with the implicature processing literature, children below 3 years struggled to make ad-hoc implicatures in the current task. Interestingly, rather than looking equally at the inferential target and distractor, 2-year-olds looked more to the distractor, and unlike other age groups, made more switches from the target to distractor even after hearing the target noun. Thus, 2-year-olds seem to have had difficulty disengaging from the distractor that was relatively more salient. These findings support the inhibitory hypothesis, namely that young children struggle with implicature tasks because they need to inhibit responses to a relatively more salient object. In Experiment 1B, we sought to test this hypothesis using the salience manipulation discussed in Introduction. 

# Experiment 1B

In Experiment 1A, we confirmed previous findings that children of 4 years and above succeed in ad-hoc implicature computation whereas younger children struggle. We also saw preliminary evidence that younger children’s failures can be attributed to their difficulty to inhibit attention away from the distractor. Experiment 1B further explored this inhibitory hypothesis. We used the same stimuli as Experiment 1A but added an extra feature to the distractor in inference trials to make it more salient, in order to increase the salience contrast between the target and distractor. For example, when the inferential target was a plate with only a carrot, the distractor was a plate with a carrot, banana, *and cucumber*.

As explained earlier, the salience manipulation will lead to different predictions based on which aspect of the context is primarily used: salience vs. pragmatics. If children are influenced more by *salience* due to the difficulty of inhibitory control, then they will incorrectly look more toward the salient distractor. On the other hand, if children are influenced more by contextual strengthening of implicature, upon hearing “Grover’s plate has a carrot” and recognizing two unnamed extra features (banana and cucumber) on the distractor, then they will correctly identify and attend to the inferential target (plate with only a carrot) as the referent.


## Method

### Participants

Participants were recruited as in Experiment 1A. A total of 129 children were recruited but a few of them were excluded from the sample for the following reasons: age other than 2 to 5 years (*n* = 2), parent-reported English exposure less than our prespecified criterion of 75% (*n* = 17), noncompliance or difficulty with the experimental procedure (*n* = 1), experimenter error or technical issues (*n* = 1). The final sample consisted of 100 (out of 108 qualifying participants; see Table 1).

### Stimuli 

The stimuli were identical to Experiment 1A, except for one change: distractor items in inference trials and target items in control-double trials now had three features instead of two (see bottom panels in Figure 1).

### Design and Procedure

The design and procedure were identical to Experiment 1A.

## Results and Discussion

```{r expt2ana}
ms <- d_et %>%
  filter(age_group != "adult") %>%
  mutate(age_group = as.numeric(as.character(age_group)),
         trial_type = relevel(as.factor(trial_type), ref = "control-single")) %>%
  filter(t.crit > .8 & t.crit <= 3) %>%
  group_by(expt,trial_type, age_group, subid, stimulus) %>%
  summarise(correct = mean(correct, na.rm = TRUE))

expt2.acc.lmer <- lmer(correct ~ trial_type * age_group + (trial_type | subid) + (1 | stimulus), 
                       data = filter(ms, expt == "3-vs-1"))

expt2.acc.cd.beta <- round(summary(expt2.acc.lmer)$coef[2], 2)
expt2.acc.inf.beta <- round(summary(expt2.acc.lmer)$coef[3], 2)
expt2.acc.age.beta <- round(summary(expt2.acc.lmer)$coef[4], 2)
```

```{r expt2ttest}
ms <- d_et %>%
  filter(t.crit > 0.78 & t.crit <= 3) %>%
  group_by(expt, trial_type, age_group, subid) %>%
  summarise(correct = mean(correct, na.rm = TRUE))

# t-tests for inference trials, by age
expt2.ttest.acc.2y = t.test(filter(ms, expt == "3-vs-1" & age_group == "2" & trial_type == "inference")$correct, mu=.5)
expt2.ttest.acc.3y = t.test(filter(ms, expt == "3-vs-1" & age_group == "3" & trial_type == "inference")$correct, mu=.5)
expt2.ttest.acc.4y = t.test(filter(ms, expt == "3-vs-1" & age_group == "4" & trial_type == "inference")$correct, mu=.5)
expt2.ttest.acc.5y = t.test(filter(ms, expt == "3-vs-1" & age_group == "5" & trial_type == "inference")$correct, mu=.5)

# referents for 2yr
expt2.ttest.acc.2y.df = round(expt2.ttest.acc.2y$parameter, 2)
expt2.ttest.acc.2y.t = round(expt2.ttest.acc.2y$statistic, 2)
expt2.ttest.acc.2y.p = round(expt2.ttest.acc.2y$p.value, 3)

# referents for 4yr
expt2.ttest.acc.4y.df = round(expt2.ttest.acc.4y$parameter, 2)
expt2.ttest.acc.4y.t = round(expt2.ttest.acc.4y$statistic, 2)
expt2.ttest.acc.4y.p = round(expt2.ttest.acc.4y$p.value, 3)

# referents for 5yr
expt2.ttest.acc.5y.df = round(expt2.ttest.acc.5y$parameter, 2)
expt2.ttest.acc.5y.t = round(expt2.ttest.acc.5y$statistic, 2)
expt2.ttest.acc.5y.p = round(expt2.ttest.acc.5y$p.value, 3)
```

### Accuracy

As in Experiment 1A, children of all age groups identified the target in both types of control trials (Figure 1). However, there was no evidence of performance above or below chance for any of the age groups in inference trials (4-year-olds: $t$: $t$(`r expt2.ttest.acc.4y.df`) = `r expt2.ttest.acc.4y.t`, $p$ =`r expt2.ttest.acc.4y.p`; 5-year-olds: $t$: $t$(`r expt2.ttest.acc.5y.df`) = `r expt2.ttest.acc.5y.t`, $p$ =`r expt2.ttest.acc.5y.p`).

A linear mixed-effects model predicting accuracy based on age and trial type in Experiment 1B showed a significant main effect of trial type ($\beta$ = `r expt2.acc.inf.beta`, $p <.001$), such that looking at target was lower in inference trials than in control trials. There was no significant main effect of age or interaction between age and trial type (largest $\beta$ = `r expt2.acc.inf.beta`, $p >.19$). Thus, there was no improvement in looking to the correct target with age increase. As in Experiment 1A, there was no order effect (largest $\beta$ = 0.09, $p >.05$).

```{r expt2rt}
et_rt_ms <- et_rts %>%
  ungroup() %>%
  filter(age_group != "adult") %>%
   mutate(age_group = as.numeric(as.character(age_group)),
         trial_type = relevel(as.factor(trial_type), ref = "control-single")) %>%
  group_by(trial_type, expt, age_group, stimulus, subid) %>%
  summarise(rt = mean(rt))

expt2.rt.lmer <- lmer(rt ~ trial_type * age_group + (trial_type | subid) + (age_group | stimulus), data=filter(et_rt_ms, expt == "3-vs-1"))

expt2.rt.inf.beta <- round(summary(expt2.rt.lmer)$coef[3], 2)
expt2.rt.age.beta <- round(summary(expt2.rt.lmer)$coef[4], 2)
expt2.rt.int.beta <- round(summary(expt2.rt.lmer)$coef[6], 2)

expt12.rt.lmer <- lmer(rt ~ expt * trial_type * age_group + (trial_type | subid) + (age_group | stimulus), data=et_rt_ms)
```

### Switch time

A linear mixed-effects model predicting the switch time, or time to make the first switch from the distractor to target after the target noun onset, based on age and trial type found a significant main effect of trial type ($\beta$ = `r expt2.rt.inf.beta`, $p =.028$) and age ($\beta$ = `r expt2.rt.age.beta`, $p =.0078$) on the average RT, with no interaction ($\beta$ = `r expt2.rt.int.beta`, $p >.23$). Thus, as in Experiment 1A, participants’ looking was faster with increasing age, and looking to inferential targets was slower than to unambiguous targets.

```{r expt12tab, echo = F, results = 'asis'}
ms <- d_et %>%
  filter(age_group != "adult") %>%
  mutate(age_group = as.numeric(as.character(age_group)),
         trial_type = relevel(as.factor(trial_type), ref = "control-single")) %>%
  filter(t.crit > .8 & t.crit <= 3) %>%
  group_by(expt,trial_type, age_group, subid, stimulus) %>%
  summarise(correct = mean(correct, na.rm = TRUE))

expt12.acc.lmer <- lmer(correct ~ expt * trial_type * age_group + (trial_type | subid) + (age_group | stimulus), 
                       data = ms)

e12.tab <- as.data.frame(summary(expt12.acc.lmer)$coef)

e12.tab$Predictor <- c("Intercept",
                      "Experiment 1B",
                      "Control-double",
                      "Inference",
                      "Age",
                      "Experiment 1B * Control-double",
                      "Experiment 1B * Inference",
                      "Experiment 1B * Age",
                      "Control-double * Age",
                      "Inference * Age",
                      "Experiment 1B * Control-double * Age",
                      "Experiment 1B * Inference * Age"
                      )
rownames(e12.tab) <- NULL
e12.tab <- e12.tab[,c(4,1:3)]
names(e12.tab)[4] <- c("$t$ value")

print(xtable(e12.tab,
             align = c("l","l","r","r", "r"),
             label = "tab:exp2_tab",
             caption = "Predictor estimates with standard errors and significance information for a linear mixed-effects model predicting accurate looking to target in Experiments 1A and 1B."),
      include.rownames=FALSE,hline.after=c(0,nrow(e12.tab)),
      sanitize.text.function=function(x){x},
      caption.placement = 'bottom', 
      table.placement = "tb",
      comment = F)

```

### Comparison between Experiment 1A and 1B

To determine the effect of salience contrast on children's inferential processing, we compared looking at targets across both Experiment 1A and 1B for inference trials. A linear mixed-effects model predicting accuracy based on experiment, age, and trial type (Table 3) revealed significant main effects of trial type and age, but no interaction between Experiment 1B and any other variable. Thus, in contrast to our initial predictions, we did not find evidence of the effect of perceptual salience on children's looking patterns. Additionally, in both Experiments 1A and 1B, we found lower proportion of look toward inferential target than expected from older children, rarely exceeding 65%. 

## Discussion

In Experiment 1B, across all ages, children looked more toward neither the inferential target nor the distractor. This was surprising, given that 4- to 5-year-olds successfully identified the inferential targets in Experiment 1A. As we predicted earlier, children may rely on either salience-based or pragmatics-based processing strategy; it is possible that children were affected by both aspects, but the strengthened implicature canceled out the effect of salience contrast. 

Another possibility is that children relied more on one cue over the other, but they simply needed more time to explore and process all that is displayed, especially with more items to be examined. One limitation of the current paradigm was that the end of each trial was not contingent upon children’s inferential decision, and did not guarantee sufficient time for its completion. To keep the task engaging and fast-paced, every trial in Experiment 1A and 1B had an approximately three-second window for recording children’s eye gazes, but younger children may have needed longer to process and interpret the utterance. To address this potential limitation, we designed another experiment, where we used another time-sensitive paradigm: a tablet study, which offers ample time for decision-making while keeping the task engaging.

# Experiment 2

In Experiment 2, we tested the effects of salience contrast using a tablet paradigm. One advantage of the tablet paradigm over eye-tracking in Experiment 1A and 1B is the high level of feedback contingency on participant responses; we provided feedback immediately following participant responses (transition to the next phase), which not only made the task more engaging, but also allowed trials to finish after participants have provided their answers, rather than ending after some arbitrary amount of time. Participants were also tested on both 2-vs-1 and 3-vs-1 trials, making it possible to test the effect of salient contrast manipulation within subjects. 

## Method

### Participants

Participants were recruited as in Experiment 1A, except that a part of the sample was recruited from a local nursery school. A total of 123 children were recruited but a few were excluded from the sample for the following reasons: age other than 2 to 5 years (*n* = 3), parent-reported English exposure less than our prespecified criterion of 75% (*n* = 5), parental interference (*n* = 2), noncompliance or difficulty with the experimental procedure (*n* = 9). The final sample consisted of 98 (out of 104 qualifying participants; see Table 1).

### Stimuli 

Items in the visual stimuli used the same set of images as in Experiment 1A, presented on a tablet. Same auditory stimuli were used as in Experiment 1A. 

### Design

The design was identical to Experiment 1B, except that each participant saw two possible variations of the number of features for each trial type (2-vs-1 and 3-vs-1 for inference and control-double trials, 1-vs-1 and 2-vs-2 for control-single trials). There were no filler trials.

### Procedure

An experimenter introduced children to the task using a tablet. Then they completed two practice trials, where they were asked to select an obvious, unambiguous referent (e.g., “cow” as opposed to “rabbit”), followed by 16 test trials. 


## Results

```{r etipad_datamunge, include=FALSE}
###### data munging #######
d_et_comp <- d_et %>%
  filter(t.crit > 0.78 & t.crit <= 3) %>%
  mutate(item_num = expt) %>%
  select(item_num, age_group, trial_type, t.crit, correct, subid) %>%
  mutate(correct = as.factor(correct))
levels(d_et_comp$correct) <- c(0,1)
d_et_comp$correct <- as.numeric(as.character(d_et_comp$correct))

d_et_comp <- d_et_comp %>%
  mutate(trial_type = as.factor(trial_type)) %>%
  group_by(age_group, trial_type, item_num, subid) %>%
  summarise(correct = mean(correct, na.rm = TRUE))
levels(d_et_comp$trial_type) <- c("control-double", "control-single", "inference")
d_et_comp$expt <- "eye-tracking"

d_ip_comp <- d_ip %>%
  select(age_group, trial_type, item_num, correct, subid) %>%
  mutate(item_num = ifelse(item_num == "2vs1", "2-vs-1", "3-vs-1")) %>%
  group_by(age_group, trial_type, item_num, subid) %>%
  summarise(correct = mean(correct, na.rm = TRUE))
d_ip_comp$expt <- "iPad"

# combine the two 
d_comp <- rbind(d_et_comp, d_ip_comp)
#######################
```

```{r ipaccrt, fig.pos = "H", echo=FALSE, message=FALSE, fig.width = 6, fig.height = 4.5, fig.align='center', fig.cap='Accuracy rates and reaction times in Experiment 2. Orange lines represent trials in which there were less features present (2-vs-1 for control-double and inference, 1-vs-1 for control-single) and green lines represent trials with more features (3-vs-1 for control-double and inference, 2-vs-2 for control-single).'}
grid::grid.raster(png::readPNG("figs/ip_accrt2.png"))
```

```{r expt3lm}
ms <- d_ip %>%
  mutate(age_group = as.numeric(as.character(age_group)),
         trial_type = relevel(as.factor(trial_type), ref = "control-single")) %>%  
  group_by(age_group, trial_type, item_rel, subid) %>%
  summarize(correct = mean(correct, na.rm=TRUE))

expt3.acc.lmer <- lmer(correct ~ trial_type * age_group * item_rel + (trial_type + item_rel | subid), data=ms)

expt3.acc.inf.beta <- round(summary(expt3.acc.lmer)$coef[3], 2)

# t-tests for inference trials, by age
expt3.ttest.acc.2y = t.test(filter(ms, age_group == "2" & trial_type == "inference")$correct, mu=.5)
expt3.ttest.acc.3y = t.test(filter(ms, age_group == "3" & trial_type == "inference")$correct, mu=.5)

# referents for 2yr
expt3.ttest.acc.2y.df = round(expt3.ttest.acc.2y$parameter, 2)
expt3.ttest.acc.2y.t = round(expt3.ttest.acc.2y$statistic, 2)
expt3.ttest.acc.2y.p = round(expt3.ttest.acc.2y$p.value, 3)

# referents for 3yr
expt3.ttest.acc.3y.df = round(expt3.ttest.acc.3y$parameter, 2)
expt3.ttest.acc.3y.t = round(expt3.ttest.acc.3y$statistic, 2)
expt3.ttest.acc.3y.p = round(expt3.ttest.acc.3y$p.value, 3)

```

```{r expt3tb, echo = F, results = 'asis'}
e3.tab <- as.data.frame(summary(expt3.acc.lmer)$coef)

e3.tab$Predictor <- c("Intercept",
                      "Control-double",
                      "Inference",
                      "Age",
                      "3-vs-1",
                      "Control-double * Age",
                      "Inference * Age",
                      "Control-double * 3-vs-1",
                      "Inference * 3-vs-1",
                      "Age * 3-vs-1",
                      "Control-double * Age * 3-vs-1",
                      "Inference * Age * 3-vs-1"
                      )
rownames(e3.tab) <- NULL
e3.tab <- e3.tab[,c(4,1:3)]
names(e3.tab)[4] <- c("$t$ value")

print(xtable(e3.tab,
             align = c("l","l","r","r","r"),
             label = "tab:exp3_tab",
             caption = "Predictor estimates with standard errors and significance information for a linear mixed-effects model predicting accurate selection of target in Experiment 2."),
      include.rownames=FALSE,hline.after=c(0,nrow(e3.tab)),
      sanitize.text.function=function(x){x},
      caption.placement = 'bottom', 
      table.placement = "tb",
      comment = F)

expt3.acc.int1.beta <- round(summary(expt3.acc.lmer)$coef[9], 2)
expt3.acc.int2.beta <- round(summary(expt3.acc.lmer)$coef[12], 2)


```

### Accuracy
As in Experiment 1A and 1B, children across all ages were able to identify the target in control trials. In inference trials, all age groups showed higher accuracy than in eye-tracking (Figure 3). 4- and 5-year-olds’ performances were nearly at ceiling, and even 3-year-olds chose the inferential target above chance ($t$(`r expt3.ttest.acc.3y.df`) = `r expt3.ttest.acc.3y.t`, $p$ < 0.001). 2-year-olds’ performance did not differ from chance ($t$(`r expt3.ttest.acc.2y.df`) = `r expt3.ttest.acc.2y.t`, $p$ =`r expt3.ttest.acc.2y.p`). 

A linear mixed-effects model predicting accuracy based on age, trial type and number of features (salience contrast; 2-vs-1 vs. 3-vs-1) showed a significant negative interaction of inference trial and 3-vs-1 ($\beta$ = `r expt3.acc.int1.beta`, $p = .036$). Thus, unlike control trials in which children’s performances did not differ by salience contrast, inference trials showed lower accuracy overall than 2-vs-1. This result was in support of our initial hypothesis that salience contrast may lead to greater struggle with the implicature task due to a higher demand for inhibiting response to distractor with greater salience. 

```{r expt3rt}
ip_rt_ms <- d_ip %>%
  filter(correct == "1") %>%
  mutate(age_group = as.numeric(as.character(age_group)),
         trial_type = relevel(as.factor(trial_type), ref = "control-single")) %>%  
  group_by(trial_type, item_rel, age_group, subid) %>%
  summarise(rt = mean(rt))

expt3.rt.lmer <- lmer(rt ~ trial_type * age_group * item_rel + (1 | subid), data=ip_rt_ms)

expt3.rt.age.beta <- round(summary(expt3.rt.lmer)$coef[4], 2)
```

### Reaction time

Developmental gains in speed of implicature processing were clear: with increasing age, children computed implicatures and identified the target faster (Figure 3). As we suspected earlier, 2- and 3-year-olds needed longer time than 3 seconds on average to indicate their answers, which may partially explain younger children’s flat performances in Experiments 1A and 1B. A linear mixed-effects model predicting reaction time based on age, trial type and number of features present showed a significant main effect of age ($\beta$ = `r expt3.rt.age.beta`, $p < .001$). Thus, children identified the correct referent faster increasingly with age across all trial types. 

## Discussion

Developmental gains in speed and accuracy in utterance processing for both control and inferential trials were clear in Experiment 2. Accuracy increased and reaction times decreased with age, indicating that children become more skilled at implicature computation as they get older. All age groups showed higher accuracy rates in Experiment 2 compared to Experiments 1A and 1B. One possible reason is that “accuracy” in a referent selection paradigm that requires a conscious decision-making (tablet) is different from “accuracy” in an eye-tracking paradigm that tracks an unconscious decision-making process. 

We also found the effect of salience contrast that we predicted earlier: namely that greater salience contrast leads to greater difficulty for children to inhibit reacting to the more salient distractor and choose the less salient target. This means that children were affected more by salience in salience-pragmatics tradeoff, and their struggle with inhibitory control outweighed the implicature strengthening support. Why did older children, who are very much capable of computing implicatures, not benefit from this implicature strengthening more? Perhaps their performance, which was already at ceiling, could not be improved further.

Why did the effect of salience contrast show up in tablet paradigm, but not in eye-tracking? One possible explanation is that the amount of time provided for inferential decision-making was too short in eye-tracking. To provide their answers on tablet, 2- and 3-year-old children often needed longer than 3 seconds, which was the average amount of time allowed on eye-tracking for children to indicate their “answers” with their eye gaze. Another possibility is that the salience-pragmatic interaction may affect decision processes differently in an eye-tracking vs. tablet paradigm. This possibility may be related to the reason why 4- and 5-year-old children consistently gave accurate answers on tablet across both 2-vs-1 and 3-vs-1, whereas they showed evidence of implicature computation only in 2-vs-1 but not in 3-vs-1 in eye-tracking. Perhaps older children’s search processes for the referent (as indicated by eye-tracking), but not their final decisions (as indicated by tablet), were affected by salience contrasts.

# General Discussion 

In two Experiments, we confirmed 3- to 5-year-old children’s successes on ad-hoc implicature computation, and saw substantial developmental gains in their accuracy and speed. Across both eye-tracking and tablet paradigms, 4- and 5-year-old children successfully computed ad-hoc implicatures and identified the inferential targets, consistent with previous findings. In the tablet paradigm, we found evidence of successful implicature computation even in three-year-olds. Between 2 and 5 years, there was clear improvement in processing skills with increasing age, such that correct referent identification was more accurate and faster in both paradigms. Thus, these findings add to the existing literature to attest to children’s growing proficiency in pragmatic processing, not only in accuracy but also in speed. 

We found evidence for the inhibitory hypothesis, that one cause of toddlers’ struggle with implicature processing is inhibitory control. In the eye-tracking paradigm, 2-year-olds looked more to the distractor than the inferential target, and they tended to switch their looking more from the target to the distractor than from the distractor to the target. These findings suggested that 2-year-olds struggled to overcome the effect of distractor salience to look to the inferential target. Through manipulation of salience contrast between inferential targets and distractors, we also found evidence in the tablet paradigm that children have more difficulty with identifying the inferential target when the salience contrast is greater. 

Our findings take an important step toward a comprehensive account of the development of implicature processing. By 2 years of age, children begin to be aware that informativeness is important to communication, but our findings suggest that their poor inhibitory control restrains processing of complicated pragmatic inferences. By 3-4 years, their inhibitory control is more developed, and they start to compute ad-hoc implicatures, albeit slowly, when access to relevant alternatives to the speaker’s words are provided in context [@barner2011]. Children then continue to develop in many ways that contribute to pragmatic processing, including via changes in processing speed [@kail1991], executive function [@davidson2006; @diamond1996], and knowledge of inferential alternatives [@barner2011; @skordos2016; @horowitzSchneider]. 

Our work also contributes to the literature by broadening of the scope of methodologies to use to examine children’s inferential processes. The eye-tracking and tablet paradigms showed improvements in implicature processing across age, not only in accuracy but also in speed. The two paradigms nicely complemented each other in that some patterns in children’s performances that were masked in one paradigm were revealed in the other (e.g., 3-year-olds’ implicature computation on tablet but not eye-tracking; see Appendix). These findings indicate the importance of using a variety of time-sensitive methods to probe children’s pragmatic processing. 

There are several limitations to be addressed about our work. First, our salience manipulation involved manipulation of the number of features present on an item, which might have caused a potential confound between salience and processing time. Children’s greater looking to the distractor might have been caused by a real desire to acquire more information, rather than the mere perceptual salience of the distractors. Second, a statistical comparison between the eye-tracking and tablet findings is not appropriate, because target identification is measured differently. Eye-tracking measures the proportion of looking toward target vs. distractor over a period of time, whereas tablet measures a single response for referent selection. Thus, it is difficult to make strong inferences about the discrepancies (e.g., different accuracy rates). Future work measures in one methodology both the time course of attentional trajectories and the speed and accuracy of final referent identification will be useful. 

In sum, our work shows evidence that from at least 3 years, children are able to compute ad-hoc implicatures, and that younger children’s failures are likely related to effects of perceptual salience of distractor items. Tasks that have typically been used to look at children’s implicature processing have a variety of extraneous processing demands, which may explain why it has been difficult to see children’s underlying pragmatic abilities beyond those extraneous skills. Our work demonstrates the importance of using a range of methods to measure children’s pragmatic processing.

\newpage

# Appendix A: Subtracting baseline bias in eye-tracking

```{r et_diff, fig.pos = "H", echo=FALSE, message=FALSE, fig.width = 6, fig.height = 4.5, fig.align='center', fig.cap='Increase in look to the target (from the offset of the target noun to 3 seconds after the target noun is produced) compared with baseline looking (from 1 second before the target noun to the start of the target noun).'}
grid::grid.raster(png::readPNG("figs/et_diff.png"))
```

In Experiments 1A and 1B, while older children (4- and 5-year-olds) looked to the inferential target above chance, younger children (2-year-olds) tended to look to the target below chance and looked more toward the distractor. The bias in toward distractor was displayed by all age groups before the start of the target noun in inference trials, which suggested that all participants were initially drawn toward the distractor that had more features and thus was more felicitous. 

We hypothesized that the difficulty in inhibiting looks to the more felicitous item caused younger children's struggle to look to the correct answer. We tested this hypothesis by subtracting initial baseline looking to target before start of target noun from look to target after target noun offset. Supporting our hypothesis, increase in participants' look to target reveals that, whereas 3- to 5-year-olds increase their look to the target, 2-year-olds do not show change in attention toward the target (see Figure 4). Thus, it is possible that 2-year-olds' identification of the inferential target was hindered by the demand to inhibit looks to the salient distractor.

# Appendix B: Comparing between eye-tracking vs. tablet

```{r etip_comp, fig.pos = "H", echo=FALSE, message=FALSE, fig.width = 6, fig.height = 4.5, fig.align='center', fig.cap='Accuracy and reaction times rates for control-double and inference trials (columns) in eye-tracking vs. tablet (iPad) paradigm (colors). Solid lines (circles) represent 2-vs-1 conditions and dashed lines (triangles) represent 3-vs-1 conditions.'}
grid::grid.raster(png::readPNG("figs/etip_comp1.png"))
```

Comparison of accuracy and reaction time measures from the eye-tracking paradigm (Experiments 1A and 1B) and tablet paradigm (Experiment 2) shows that robust implicature computation by 3- to 5-year-olds is much more clearly revealed in the tablet paradigm than in the eye-tracking paradigm (Figure 5). In fact, accuracy for inferential trials in the tablet paradigm was overall higher than what was reported in Stiller et al. (2015), possibly due to stimuli that were even more simplified (two referent candidates instead of three). The tablet paradigm also revealed the developmental gains in both accuracy (left in Figure 5) and speed (right) more prominently than eye-tracking.

```{r etip_rel_tab, echo = F, results = 'asis'}

age_group <- c("2", " ", "3", " ", "4", " ", "5", " ")
paradigm <-c("eye-tracking", "tablet","eye-tracking", "tablet","eye-tracking", "tablet","eye-tracking", "tablet")
mean_trials_acc <- c("10.48", "11.44", "10.44", "11.55", "10.89", "12.00", "10.62", "11.84")
alpha_acc <- c(".43", ".78", ".66", ".84", ".61", ".42", ".57", ".20")
mean_trials_rt <- c("3.53", "15.16", "3.42", "15.17", "2.87", "16.00", "3.55", "15.68")
alpha_rt <- c(".45", ".29", ".77", ".79", "-.33", ".86", "-.12", ".65")
e5.tab <- data.frame(age_group, paradigm, mean_trials_acc
                     , alpha_acc, mean_trials_rt, alpha_rt)
colnames(e5.tab) <- c("Age bin", "Paradigm", "M trials (acc)"
                      , "alpha accuracy", "M trials (RT)", "alpha RT")

print(xtable(e5.tab,
             align = c("l", "l","c","c","c", "c","c"),
             label = "tab:etip_rel",
             caption = "Standardized reliability coefficients (Cronbach's alpha) for accuracy (acc) and reaction time (RT) by paradigm and age group, along with the mean number of trials for each."),
      include.rownames=FALSE,hline.after=c(0,nrow(e5.tab)),
      sanitize.text.function=function(x){x},
      caption.placement = 'bottom', 
      table.placement = "tb",
      comment = F)

```

<!--reliability: cronbach's alpha-->
We also examined whether our study measured the variable of interest with good reliability, by computing Cronbach’s $\alpha$, a statistic that determines the internal consistency of experimental items [@santos1999cronbach]. Across both eye-tracking and tablet paradigms, our study contained three trial types (control-single, control-double, and inference), with 8, 4, and 4 trials respectively, a small number on which to compute reliability statistics. To assess reliability, we examined non-inference (control) trials and computed a reliability coefficient for each experiment and age group, for both accurate looking and reaction times (see Table 5). 

Overall, reliability estimates looked reasonable for accuracy and reaction time, with a few aspects to be noted. For accuracy, younger children showed decent reliability in both paradigms, whereas older children had low reliability in the tablet paradigm, likely due to a ceiling effect. For reaction time, reliability was generally higher for tablet paradigms, especially among older children. It should be noted that reaction time reliability for eye-tracking was computed with very sparse data (2-3 trials). Thus, the tablet paradigm overall more clearly and more reliably showed children's success in implicature computation compared to eye-tracking.

\newpage

# References 




